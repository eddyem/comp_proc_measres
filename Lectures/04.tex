\lr{Теория оценок}
\subsection{Правило <<трех сигм>>}
Для вычисления вероятности попадания случайной величины, имеющей нормальное
распределение, в заданный интервал~$[a,b]$, используются функции Лапласа.
Вероятность того, что случайная величина~$x$ лежит в интервале
$[\mean{x}-\delta,\mean{x}+\delta]$ равна
$$P(|x-\mean{x}|<\delta)=2\Phi(\delta/\sigma).$$
Если $\delta=3\sigma$, то вероятность попадания случайной величины в данный
отрезок будет равна
$$P(|x-\mean{x}|<3\sigma)=2\Phi(3)=0.9973.$$
Другими словами, вероятность того, что абсолютная величина отклонения случайной
величины от ее математического ожидания превысит утроенное среднеквадратическое
отклонение, составляет~$0.27\%$.

Этот вывод называют\ж правилом трех сигм\н\index{Правило трех сигм}:\к если
случайная величина распределена нормально, то абсолютная
величина ее отклонения от математического ожидания не превосходит утроенного
среднего квадратичного отклонения\н.

На практике правило трех сигм применяют так: если распределение случайной
величины неизвестно, но условие, указанное в приведенном правиле, выполняется,
то есть основание предполагать, что изучаемая величина распределена нормально.
В противном случае она имеет другой вид распределения.

Кроме того, правило трех сигм обычно используют для отбора заведомо ложных
результатов измерения~--- промахов: все величины, отклоняющиеся от
математического ожидания (или медианы, что более точно) более, чем на утроенное
среднеквадратическое отклонение, считаются промахами и исключаются из
дальнейших расчетов.

Согласно\ж теореме Ляпунова\н\index{Теорема!Ляпунова},\к случайная величина,
являющаяся суммой большого
числа взаимно независимых случайных величин, имеет нормальное распределение\н.
Так как результат физического измерения определяется огромным количеством
случайных величин (давление, температура, магнитное поле Земли и~т.п.),
любой результат физического измерения имеет нормальное распределение.

\subsection{Распределение <<хи квадрат>>}
Так как при измерении реальных (эмпирических) случайных величин ограничиваются
конечным (и обычно небольшим) количеством измерений, вид распределения
данной величины может отличаться от гауссова распределения.

Пусть~$x_i$, $i=\overline{1,n}$~--- нормальные независимые случайные величины,
математическое ожидание которых, $\mean{x}=0$, а среднеквадратическое
отклонение, $\sigma_x=1$. Тогда сумма квадратов этих величин
$\chi^2=\sum_{i=1}^n x_i^2$
распределена по закону <<\bf{}хи квадрат\rm>>\index{Распределение!хи квадрат}
с~$k=n$ степенями свободы.
Каждое линейное соотношение между этими величинами, например, $\sum x_i
=n\mean{x}$, уменьшает количество
степеней свободы распределения на единицу.

Плотность распределения <<хи квадрат>>:
$$
f(x)=\begin{cases}
0,& x\le0,\\
\dfrac{\e^{-x/2}x^{k/2-1}}{2^{k/2}\Gamma(k/2)},& x>0,\\
\end{cases}
$$
где $\Gamma(x)=\Int_0^\infty t^{x-1} e^{-t}dt$~-- гамма-функция, в частности,
$\Gamma(n+1)=n!$.
Отсюда видно, что с увеличением степеней свободы~$k$ распределение <<хи
квадрат>> приближается к нормальному распределению (что соответствует закону
больших чисел).

\subsection{Распределение Стьюдента}
Если $z$~-- нормальная случайная величина с $\mean{z}=0$ и~$\sigma_z=1$, а
$v$~-- независимая от~$z$ величина, распределенная по закону~$\chi^2$ с~$k$
степенями свободы, то величина
$$T=Z/\sqrt{V/k}$$
имеет распределение, которое называют\ж t-распределением\н или\ж распределением
Стьюдента\н\index{Распределение!Стьюдента}.

Распределение Стьюдента при увеличении числа степеней свободы быстро
приближается к нормальному.

\subsection{Теория оценок}
Из-за того, что количество экспериментов (т.е. наблюдаемых величин) при
измерении физической величины ограничено конечным (небольшим) числом, для
определения как можно более точного значения математического ожидания данной
величины используется\к теория оценок\н.

\bf Статистической оценкой\н\index{Оценка} неизвестного параметра
теоретического распределения называют функцию от наблюдаемых случайных величин.

\bf Несмещенной\н называют оценку величины~$x$, совпадающую
с~$\mean{x}$, однако, действительные оценки являются смещенными.\ж Эффективной\н
называют оценку с наименьшей дисперсией.\ж Состоятельной\н называют оценку,
стремящуюся при увеличении количества наблюдаемых к~$\mean{x}$.

Аналогично характеристикам случайных величин, для выборок вводят понятие
группового и общего среднего, генеральной и выборочной дисперсии. В качестве
оценки дисперсии выборки обычно принимают\ж исправленную
дисперсию\н\index{Дисперсия!исправленная}
$D=\frac{n}{n-1}D\ind{выб}$. Т.е. при расчете дисперсии суммы квадратов
отклонений наблюдаемых от их среднего значения необходимо делить на число
наблюдаемых без единицы.

\bf Точностью\н\index{Точность} оценки (или доверительным интервалом)~$\delta$
называют длину полуинтервала, в котором с определенной вероятностью находится
измеряемая величина. Соответствующую вероятность~$\gamma$ называют\ж
надежностью\н\index{Надежность} оценки.
Т.о.,~получим соотношение:
$$
P(|x-\mean{x}|<\delta)=\gamma.
$$

Примем, что если случайная величина~$x$ распределена нормально, ее выборочная
средняя~$\aver{x}$ также распределена нормально. В этом
случае~$\mean{\aver{x}}=a$ и
$\sigma_{\aver{x}}=\sigma/\sqrt{n}$, где~$a$ и~$\sigma$~-- математическое
ожидание и среднеквадратичное отклонение случайной величины~$x$.
В этом случае для надежности оценки получим:
$$
\gamma\equiv P(\aver{x}-\delta<a<\aver{x}+\delta)=2\Phi(\delta\sqrt{n}/\sigma).
$$

Однако, чаще всего для данной наблюдаемой~$\sigma$ неизвестно. В этом случае
можно оценить доверительный интервал при помощи распределения Стьюдента.

По данным выборки можно построить случайную величину 
$$t=\frac{\aver{x}-\mean{x}}{S/\sqrt{n}},$$
которая имеет распределение Стьюдента с $k=n-1$ степенями свободы. Здесь
$S=\sqrt{D}$~-- <<исправленное>> среднеквадратическое отклонение, $n$~-- объем
выборки.

В этом случае параметры распределения определяются так:\label{gammaS}
$$
\gamma\equiv
P(\bigl|\frac{\aver{x}-\mean{x}}{S/\sqrt{n}}\bigr|<t_\gamma)=2\Int_0^{t_\gamma}
S(t,n)\,dt,\qquad
\delta=\frac{t_\gamma S}{\sqrt{n}},
$$
параметр~$t_\gamma$ для заданных~$n$ и~$\gamma$ можно найти в соответствующих
таблицах.

Итак, оценку истинного значения измеряемой величины можно произвести при помощи
доверительного интервала $[\aver{x}-\delta,\aver{x}+\delta]$, покрывающего
неизвестное математическое ожидание~$\mean{x}$ с надежностью~$\gamma$.

Случайные величины $\mean{x}$ и~$\sigma$ заменяются неслучайными величинами
$\aver{x}$ и~$S$. 

Оценку среднеквадратичного отклонения~$\sigma$ случайной величины~$x$
производят при помощи критерия <<хи квадрат>>: величина 
$$\chi=\frac{S}{\sigma}\sqrt{n-1}$$
распределена по закону <<хи квадрат>> с $k=n-1$ степенями свободы.
Вероятность $\gamma=P(|\sigma-S| <\delta)$ в этом случае равна
$$
\gamma=\Int_{\frac{\sqrt{n-1}}{1+\delta/S}}^{\frac{\sqrt{n-1}}{1-\delta/S}}
R(\chi,n)\,d\chi\equiv \mathcal{X}(n,S),
$$
где $R$~-- плотность распределения~$\chi$.

Вычислив по выборке $S$ и найдя по специальной таблице для~$S$ и
заданной~$\gamma$ величину~$q=\delta/S$, получим искомый доверительный интервал.

Однако, следует учесть, что чем меньше объем выборки, тем меньше информации
она содержит, и тем меньше надежность определения доверительного интервала.

Для оценки других характеристик распределения используется\ж метод
моментов\н\index{Метод!моментов},
согласно которому\к начальные и центральные эмпирические моменты являются
состоятельными оценками соответствующих начальных и центральных теоретических
моментов того же порядка\н.
