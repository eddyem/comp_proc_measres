\lr{Теория физических измерений. Систематические и случайные погрешности}
\subsection{Измерения и величины}
Развитие науки и техники неразрывно связано с точными измерениями, которые дают
новую информацию об окружающем физическом мире. Эксперимент служит основной
формой целенаправленного движения к познанию окружающего материального мира, то
есть важнейшим инструментом науки. Естественным и наиболее простым способом
количественного оценивания свойства является прямое сравнение двух вещей в
определенном отношении (по степени проявления свойства). Для стандартизации
измерений было разработано соглашение о единицах, используемых для измерений.
В метрологии их называют\ж мерами\н\index{Мера}.

Результатом сравнения оцениваемой вещи с мерой является именованное число,
называемое\ж значением величины\н\index{Значение}. Измерения одной и той же
величины можно проводить как однократно, так и многократно.

Физические величины можно разделить на три типа: постоянные, изменяющиеся и
случайные.
К постоянным величинам относят инварианты, чье значение доподлинно известно,
физические постоянные, а также величины, однозначно не изменяющие своего
значения в
процессе измерения. Изменяющиеся величины по определенному закону меняют
со временем свое значение. Точное значение случайной величины определить
невозможно,
можно указать лишь ее дисперсию и среднее значение. Таким образом, эксперимент
позволяет измерить с заданной точностью лишь постоянные и изменяющиеся величины.
Однако, и в этом случае точность измерения будет ограничена случайными
ошибками.

В отличие от классической механики, в квантовой механике многие физические
величины
являются связанными (например, импульс и координата), поэтому, чем больше
точность
измерения одной из связанных величин, тем меньше точность измерения другой
величины (согласно соотношению неопределенностей).

\bf Представление\н результатов физического измерения имеет немаловажное
значение
для понимания сути исследуемого процесса.\к Результаты измерения можно
представить
в виде таблиц или графиков\н. Наибольшую наглядность имеет графическое
представление.
При этом немаловажно правильно задать масштаб графика, направление осей и шкалы
осей (линейную, экспоненциальную, логарифмическую или иную). Например, для
отображения зависимости активности радиоактивного изотопа от времени, удобно
использовать линейную шкалу для активности препарата и логарифмическую~--- для
времени.

\subsection{Погрешность}
Количественной характеристикой неоднозначности результата измерения является\ж
погрешность\н\index{Погрешность}. Ее оценивают, исходя из всей информации,
накопленной при подготовке и выполнении измерений. Окончательный результат
измерения нельзя расценивать как <<истинное значение>> измеряемой физической
величины, так как в этом нет смысла из-за наличия погрешности.

Погрешность может быть выражена в единицах измеряемой величины $x$~--- в таком
случае она обозначается~$\Delta x$ и носит название\ж абсолютной
погрешности\н.
Однако абсолютная погрешность не отражает в полной мере качества измерений.
Действительно, абсолютная погрешность 1~мм при измерении размера комнаты перед
оклеиванием обоями свидетельствует о высоком качестве измерения, но та же
погрешность неприемлема при измерении, например, расстояний между атомами в
металле.

Критерием качества измерения является безразмерное отношение абсолютной
погрешности к окончательному результату измерения, $\delta x=\Delta x/x$,
которое называют\ж относительной погрешностью\н и используют как в абсолютном,
так и в процентном выражении.

Выделяют следующие виды погрешностей:
\begin{description}
\item[промахи] возникают вследствие неисправности измерительных приборов или
ошибок в эксперименте, сделанных по невнимательности;
\item[систематические погрешности] как правило, неизвестны и могут быть учтены
лишь при выполнении измерений несколькими приборами. Данная погрешность
возникает
вследствие значительной величины влияния прибора на измеряемую величину, либо же
из-за пренебрежения некоторыми величинами на этапе моделирования эксперимента;
\item[случайные погрешности] носят случайный характер (чаще всего они имеют
гауссово распределение) и возникают из-за незначительных (флуктуационных)
изменений хода эксперимента.
\end{description}

Рассмотрим мысленный эксперимент по изменению физической величины~$x$. Пусть в
результате~$n$ измерений получен ряд значений~$x_1,\ldots$, $x_n$. Для получения
действительного значения величины~$x$ необходимо, прежде всего выявить промахи,
которые могут иметь вид неестественных значений результатов измерения. При
графическом представлении результатов измерения промахи имеют вид точек,
имеющих значительное отклонение от основной группировки точек данных.
Аналитически промахи можно учесть, используя критерии трех сигм или
Стьюдента. Например, если, изучая зависимость силы тока в проводнике от
напряжения на нем, отложить на графике $(I,U)$ полученные значения в виде
точек, основная масса результатов будет группироваться около прямой линии,
проходящей в первом квадранте графика. Промахи же будут располагаться на
значительном удалении от данной прямой. Используя критерий трех сигм, вначале
вычисляют медиану~$X_M$ и среднее квадратическое отклонение~$\sigma_X$ ряда
данных. Все результаты, расположенные вне интервала $X_M\pm3\sigma_X$ считаются
промахами (т.к. в данном интервале должно располагаться более~$99\%$ данных).

Далее учитывают систематические (приборные) погрешности, которые имеют вид
поправок к результатам. Если значение систематической погрешности заранее не
известно, проводят контрольные эксперименты, результаты которых могут быть
доподлинно известны. Например, при получении изображений при помощи ПЗС-матрицы
с неизвестным зарядом нулевого смещения, для определения приборной погрешности
получают несколько кадров с нулевой выдержкой. Средний уровень сигнала на
полученных снимках и будет являться систематической погрешностью матрицы,
которая затем вычитается из результата.

Приборные погрешности обычно указываются на лицевой панели прибора или в
сопроводительной документации в виде\ж класса точности\н\index{Класс
точности}~$\sigma_p$~--- наибольшей погрешности в процентном соотношении от
предела
измерений.

Оставшиеся случайные погрешности обычно характеризуют средним квадратическим
отклонением, которое (с учетом приборной погрешности) в простейшем случае и
указывается в конечном результате в виде аддитивной погрешности. Например,
проведя серию опытов по измерению некоторой величины~$x$, после устранения
промахов и систематических погрешностей результат записывается в виде
$x\pm(\sigma_x+\sigma_p)$.

В случае, когда~$n$ имеет достаточно большую величину, погрешность
результата~$\sigma_{\mean{x}}$ уменьшается в~$\sqrt{n}$ раз по сравнению с
погрешностью отдельного измерения~$\sigma$, и выражается формулой
$$
\sigma_{\mean{x}}=\frac{\sigma}{\sqrt{n}}=
\sqrt{\frac{\sum\limits_{i=1}^n(x_i-\mean{x})^2}{n(n-1)}}.
$$

За оценку погрешности окончательного результата многократного измерения примем
величину~$\Delta x$, задающую симметричный относительно~$\mean{x}$ интервал
значений, называемый\ж доверительным интервалом\н\index{Доверительный интервал}.
Вероятность найти значение измеряемой величины в указанном интервале носит
название\ж доверительной
вероятности\н\index{Вероятность!доверительная}~$\alpha$. Для нормального
распределения существуют таблицы доверительных вероятностей в относительных
единицах~$\frc{\Delta x}{\sigma}$. Случайную величину обычно записывают в
виде
$$
x=\mean{x}\pm\Delta x,\quad \alpha=\alpha_0.
$$

Идеальным является бесконечное число измерений, однако, обычно ограничиваются
пятью-десятью замерами, что приводит к искажению оценки погрешности.
В этом случае погрешность рассчитывают по формуле
$$
\Delta x\ind{случ}=t(\alpha,n)\sigma_{\mean{x}},
$$
где $t(\alpha,n)$~-- табличные\ж коэффициенты
Стьюдента\н\index{Коэффициент!Стюдента}.

После измерения случайной погрешности результат записывают в виде $x=\mean{x}\pm
\Delta x$, где
$$
\Delta x=\sqrt{(\Delta x\ind{случ})^2+\sigma\ind{приб}^2}.
$$

Следует учесть при выполнении измерений, что\к если результаты измерений не
выходят за рамки приборной погрешности, можно уверенно считать~$\Delta
x=\sigma\ind{приб}$\н. Повышение количества измерений в этом случае не
способствует повышению точности эксперимента.

Для записи результата следует согласовывать точность измеренной величины и
погрешности: порядок значащих цифр в них долежн совпадать. Для определения
количества значащих цифр погрешности следует учесть, что\к относительная
неточность
оценивания величины~$\sigma$ составляет примерно~$(n-1)^{-1/2}$\н. Таким
образом,
точность оценки погрешности при выполнении десяти измерений составляет
около~$30\%$,
что делает бессмысленным писать более одной значащей цифры погрешности (т.е.
правильной будет запись в виде~$x=154\pm2$ и неправильной: $x=154.3\pm2.1$). Для
более наглядного представления результата можно вынести за скобки общий
множитель. Например, получив значение $\mean{x}=3954.2\cdot10^3$ при погрешности
$\Delta x=126\cdot10^2$ на основании десяти измерений, следует записать
результат в виде $x=(395\pm1)\cdot10^4$.

Для определения погрешности в случае, когда\к физическая величина определяется
аналитически, исходя из измерения нескольких физических величин\н, необходимо
придерживаться следующих\ж правил\rm.
\begin{enumerate}
\item Предельная\ж абсолютная погрешность\н суммы или разности равна сумме
абсолютных погрешностей. Пусть $Y=X_1\pm X_2$, $X_1=\mean{x_1}\pm\Delta x_1$,
$X_2=\mean{x_2}\pm\Delta x_2$, тогда 
$$Y=\mean{x_1}\pm\Delta x_1\pm(\mean{x_2}\pm\Delta x_2)=
(\mean{x_1}\pm \mean{x_2})\pm(\Delta x_1 + \Delta x_2).$$
Следовательно, $\mean{y}=\mean{x_1}\pm \mean{x_2}$,
$\Delta y=\Delta x_1+\Delta x_2$.
В общем виде:
$$\Delta\bigl(\pm\sum a_n\bigr)=\sum\Delta a_n.$$
\item Предельная\ж относительная погрешность\н произведения или частного равна
сумме относительных погрешностей (при пренебрежении величинами второго и
б\'ольших порядков малости). Как следствие: относительная погрешность $n$-й
степени случайной величины равна произведению относительной погрешности этой
величины на~$n$.
$$\prod(a_i\pm\Delta a_i)=\prod a_i\prod(1\pm\delta a_i)\approx
\prod a_i(1\pm\sum\delta a_i),$$
$$\bigl(a[1\pm\delta a]\bigr)^n\approx a^n(1\pm n\delta a).$$
Следовательно, если $Y=X_1\cdot X_2$ то $\mean{y}=\mean{x_1}\cdot\mean{x_2}$,
$\delta y=\delta x_1+\delta x_2$.

Аналогично доказывается это свойство погрешностей и для частного. Пусть
$Y=X_1/X_2$, тогда
$$\delta y=\Bigl|\frac{\mean{\bigl(\frac{X_1}{X_2}\bigr)}}{y}-1\Bigr|=
\Bigl|\frac{1\pm\delta x_1}{1\pm\delta x_2}-1\Bigr|=
\Bigl|\frac{(1\pm\delta x_1)(1\mp\delta x_2)}{(1\pm\delta
x_2)(1\mp\delta x_2)}-1\Bigr|\approx \delta x_1+\delta x_2.
$$

\item\ж В сложных функциях\н вида $y=f(x_1,\ldots,x_n)$ можно оценить
погрешность, воспользовавшись приближением:
\begin{equation}
\delta y\approx\Bigl|\frac{dy}{y}\Bigr|=\Bigl|
\frac{d f(x_1,\ldots,x_n)}{f(x_1,\ldots,x_n)}\Bigr|,
\label{pogr}
\end{equation}
в котором следует заменить $\frc{dx_i}{x_i}=\delta x_i$~-- относительная
погрешность
измерения величины~$x_i$, $d x_i=\Delta x_i$~-- абсолютная погрешность. Все
слагаемые, возникающие при расчете по формуле~\eqref{pogr} необходимо
суммировать
по абсолютной величине.

Строго говоря, замена конечных приращений дифференциалами не является
корректной с математической точки зрения. Однако, при малых величинах
погрешностей такая замена справедлива с точностью до малых второго и более
высоких порядков.
\end{enumerate}

\subsection{Метод наименьших квадратов}
Многие изменяющиеся физические величины имеют линейную зависимость. Оценить
параметры такой зависимости можно графически, либо аналитически. Графическая
оценка заключается в следующем алгоритме. На график в виде точек наносятся
значения измеренных величин. Вокруг каждой точки строится прямоугольник со
сторонами, соответствующими погрешностям измеренных величин. Далее между точками
проводится прямая так, чтобы по возможности пересечь все прямоугольники. Если на
протяжении всей прямой наблюдается примерно одинаковое количество точек над и
под ней, и при этом точки располагаются хаотически (т.е. не образуют групп,
последовательно расположенных над или под прямой), данную зависимость можно
интерпретировать как линейную. Из коэффициента наклона полученной прямой и точки
пересечения ординаты определяются параметры зависимости $X=AY+B$.

Одним из наиболее распространенных приемов статистической обработки
экспериментальных данных, относящихся к различным функциональным зависимостям
физических величин друг от друга является\ж метод наименьших
квадратов\н\index{Метод!наименьших квадратов}.

Метод наименьших квадратов широко используется в задачах аппроксимации функций
и при параметрическом анализе данных. Данный метод был предложен Гауссом для
параметрического анализа данных в следующей форме. Пусть имеется функция
$f(x|a)$, зависящая от аргумента $x$ и набора параметров~$a$. Данной функции
соответствует набор пар данных $(x_n,y_n)$, причем $y_n=f(x_n|a)+\epsilon_n$,
где $\epsilon_n$~-- случайная ошибка. Математическое ожидание ошибки
$\mean{\epsilon}=0$, ее среднеквадратическое отклонение равно~$\sigma_n$.
Для оценки~$a$ необходимо минимизировать выражение
$$\Phi=\sum_{n=1}^N\Bigl(\frac{y_n-f(x_n|a)}{\sigma^2_n}\Bigr)^2.$$
При этом подразумевается, что число измерений превышает число параметров~$a$.

В своей простейшей форме метод наименьших квадратов
применим к линейной зависимости $y=ax+b$ и позволяет получить достоверные оценки
ее параметров, $a$ и~$b$, а также оценить их погрешности.

Пусть проведено~$n$ парных измерений величин~$x$ и~$y$. По экспериментальным
данным необходимо найти оценки параметров~$a$ и~$b$, а также оценки их дисперсий
$\sigma^2_a$ и~$\sigma^2_b$. Предположим, что значения~$x_i$ известны без
погрешностей, а величины~$y_i$ распределены нормально относительно величины
$\mean{y_i}$ с одинаковыми дисперсиями~$\sigma^2_y$. Математические ожидания
$\mean{y_i}$ удовлетворяют выражению $\mean{y_i}=ax_i+b$~\look{lessquare}.

В этом случае критерий минимизации суммы квадратов отклонения
$Y=\sum(y_i-\mean{y_i})^2$
позволяет с достаточно большой вероятностью оценить величины~$a$ и~$b$.
Минимизация~$Y$ производится по обеим переменным, т.е. необходимо,
чтобы выполнялись равенства: $\partder{Y}{a}=0$ и
$\partder{Y}{b}=0$. Эти два условия образуют
систему уравнений, из которых и находятся искомые неизвестные величины:
\begin{equation}
a=\frac{n\sum x_iy_i-\sum x_i\sum y_i}{n\sum x^2_i-\Bigl(\sum x_i\Bigr)^2}=
\frac{\mean{xy}-\mean{x}\,\mean{y}}{\mean{x^2}-(\mean{x})^2},
\label{koeff_a}
\end{equation}
\begin{equation}
b=\frac{\sum x_i^2\sum y_i-\sum x_i\sum x_i y_i}{n\sum x^2_i-\Bigl(\sum
x_i\Bigr)^2}=
\frac{\mean{x^2\strut}\,\mean{\strut
y}-\mean{x}\,\mean{xy}}{\mean{x^2}-(\mean{x})^2}.
\label{koeff_b}
\end{equation}

\begin{pict}
\includegraphics[width=\textwidth]{pic/lesssquare}
\caption{Аппроксимация функций методом наименьших квадратов. Сплошная линия~---
линия тренда, звездочками обозначены экспериментальные данные}
\label{lessquare}
\end{pict}

Соответствующие дисперсии равны:
$$
\sigma^2=\frac{n}{n-2}\Bigl(\mean{y^2}-(\mean{y})^2-a^2\bigl[
\mean{x^2}-(\mean{x})^2\bigr]\Bigr),\qquad
\sigma^2_a=\frac{\sigma^2}{n\bigl(\mean{x^2}-(\mean{x})^2\bigr)},\quad
\sigma_b^2=\sigma_a^2\mean{x^2}.
$$

Найденные величины позволяют\ж аппроксимировать\н\index{Аппроксимация}
(подыскать наиболее удовлетворяющую функциональную зависимость для данного
набора данных) заданную таблично функцию $y(x)$.

В случае функции двух и более переменных $z\equiv z(x,y)=ax+by+c$
коэффициенты~$a$,
$b$ и~$c$ также можно отыскать методом наименьших квадратов. Единственным
отличием
в данном случае будет то, что система будет состоять из трех уравнений для трех
неизвестных.

Теперь предположим, что у нас имеется нелинейная функция $y=f(x)$. Даже в этом
случае возможно использовать метод наименьших квадратов, но
формулы~\eqref{koeff_a} и~\eqref{koeff_b} могут значительно видоизмениться.
Некоторые зависимости, однако, можно свести к линейным. Например, функция
$y=\e^{ax+b}$ после логарифмирования примет вид $\ln y=ax+b$. Заменяя переменную
$y_1=\ln y$ (т.е. прологарифмировав измеренные величины~$y_i$) можно определить
коэффициенты~$a$ и~$b$ по тем же формулам, что и для линейной зависимости.
Однако, следует иметь в виду, что в этом случае дисперсии~$\sigma$,
$\sigma_a$ и~$\sigma_b$ будут вычисляться немного иначе.
