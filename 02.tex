\lr{Статистика и вероятность. Случайные величины и распределения}
\subsection{Случайные величины, вероятность}
\bf Случайной величиной\н\index{Случайная величина} называется величина~$X$,
если все ее возможные значения образуют конечную или бесконечную
последовательность чисел~$x_1,\ldots$, $x_N$,
и если принятие ею каждого из этих значений есть случайное событие.

Несколько случайных событий называют\ж несовместными\н\index{Несовместные
события}, если появление одного из них исключает появление остальных событий в
том же испытании. Несколько событий образуют\ж полную группу\н, если в
результате испытания появится хотя бы одно из них.

\bf Вероятностью\н\index{Вероятность}
наступления данного случайного события~$x_k$ называется предел относительной
частоты
наступления данного события~$n_k/N$:
$$P(x_k)=\lim_{N\to\infty}\frac{n_k}{N}.$$
Из определения вероятности вытекают следующие ее свойства:
\begin{itemize}
\item вероятность достоверного события равна единице;
\item вероятность невозможного события равна нулю;
\item вероятность случайного события есть положительное число, заключенное
между единицей и нулем.
\end{itemize}

Термин\к вероятность\н справедлив относительно\ж дискретных\н случайных
величин\index{Случайная величина!дискретная}~--- величин, принимающих
отдельные, изолированные возможные значения с определенными вероятностями.
Число возможных значений дискретной случайной величины может быть конечным или
бесконечным.

Случайная величина может быть не только дискретной, но и\ж
непрерывной\н\index{Случайная величина!непрерывная}. В этом
случае она может принимать любое значение из заданной~--- конечной или
бесконечной~--- области действительных чисел.
Непрерывная случайная величина характеризуется\ж плотностью
вероятности\н\index{Плотность вероятности}:
$$\phi(x)=\lim_{\Delta x\to 0}\frac{P(x<X<x+\Delta x)}{\Delta
x}=\frac{dP}{dx}.$$
Вероятность попадания значений~$X$ в интервал~$(x_1,x_2)$ можно вычислить по
формуле:
$$P(x_1<X<x_2)=\Int_{x_1}^{x_2}\phi(x)\,dx.$$

\subsection{Характеристики случайных величин}
Две случайные величины~$X$ и~$Y$ называются\ж независимыми\н\index{Случайная
величина!независимая}, если наступление одного
из событий~$x_n$ никак не сказывается на результате события~$y_n$. В этом случае
вероятность совместного наступления событий~$x_n$ и~$y_n$ равна
$P(x_ny_n)=P(x_n)P(y_n)$.
Дальнейшие формулы в этом разделе подразумевают независимость входящих в них
случайных
величин, если зависимость не указана явно.

Набор случайных величин~$X$ можно охарактеризовать\ж средним
арифметическим\н\index{Среднее арифметическое}:
$\aver{X}=\frc1{N}\sum_{n=1}^N x_n$. Для малых~$N$ данная величина будет
отличаться
от\ж математического ожидания\н\index{Математическое ожидание}, определяемого по
формуле
$$M(X)\equiv\mean{X}=\lim_{N\to\infty}\frac1{N}\sum_{n=1}^N
x_n\quad\text{и}\quad
M(X)=\Infint x\phi(x)\,dx.$$
\it В дальнейшем для обозначения математического ожидания случайной
величины~$X$ будем использовать следующую запись: $\mean{X}$\н.
Таким образом, математическое ожидание является суммой произведений всех
возможных значений случайной величины на их вероятности (для непрерывных
случайных величин~--- интегральной суммой).

Математическое ожидание обладает следующими\к свойствами\н:
\begin{itemize}\setlength{\itemsep}{2pt}
\item $\mean\const=\const$;
\item $\mean{\sum\C_n\cdot X_n}=\sum\C_n\cdot \mean{X_n}$,
где $\C_n$~-- постоянная величина; 
\item $\mean{\prod X_n}=\prod \mean{X_n}$ (для независимых случайных величин);
\item $\mean{f(x)}=\Infint f(x)\phi(x)\,dx$ (для непрерывных случайных величин).
\end{itemize}

Вполне логично сравнить математическое ожидание случайной величины с ее средним
арифметическим, однако, насколько правомерной окажется замена
$\mean{X}\Leftrightarrow\aver{X}$?\ж Неравенство
Чебыш\"ева\н\index{Неравенство Чебыш\"ева} позволяет утверждать, что
вероятность того, что отклонение случайной величины~$X$ от ее математического
ожидания по абсолютной величине меньше положительного числа~$\epsilon$, не
меньше, чем $1-D(X)/\epsilon^2$:
$$P(|X-\mean{X}|<\epsilon)\ge 1-D(X)/\epsilon^2.$$
Из\ж теоремы Чебыш\"ева\н\index{Теорема!Чебыш\"ева} следует, что 
$$\lim_{n\to\infty} P\Bigl(\Bigl|\frac{\sum
X_n}{n}-\frac{\sum\mean{X_n}}{n}\Bigr|<\epsilon\Bigr)=1.$$
Таким образом,\к среднее арифметическое достаточно большого числа независимых
случайных величин утрачивает характер случайной величины\н.\ж Теорема
Бернулли\н\index{Теорема!Бернулли} утверждает, что если в каждом
из~$n$ независимых испытаний вероятность~$p$ появления события~$A$
постоянна, то отклонение относительной частоты от вероятности~$p$ по абсолютной
величине будет сколь угодно малым, если число испытаний достаточно велико:
$$\lim_{n\to\infty} P(|m/n-p|<\epsilon)=1.$$

Теоремы Чебыш\"ева и Бернулли являются частными случаями\ж закона больших
чисел\н\index{Закон!больших чисел}. Теорема Чебыш\"ева является наиболее общим
законом больших чисел, теорема Бернулли~--- простейшим. Упрощенно можно
сказать, что чем большей является количество испытаний~$n$, тем
ближе~$\aver{X}$ к~$\mean{X}$ и относительная частота $m/n$ к вероятности~$p$.

Помимо математического ожидания набор случайных величин характеризуется медианой
и модой.\ж Мода\н\index{Мода}~--- значение во множестве наблюдений, которое
встречается наиболее часто. Иногда мод может быть больше одной. В этом случае
можно сказать, что совокупность\к мультимодальна\н. Как правило
мультимодальность указывает на то, что набор данных не подчиняется нормальному
распределению.\ж Медиана\н\index{Медиана}~--- возможное значение
признака, которое делит отсортированную совокупность на две равные части:
50\%~<<нижних>> единиц ряда данных будут иметь значение признака не больше, чем
медиана, а 50\%~<<верхних>>~--- значения признака не меньше, чем медиана.

Если $f(x)=(x-x_0)^n$, говорят, что~$\mean{f(x)}$ является\ж
моментом\н\index{Момент} случайной величины порядка~$n$. При~$x_0=0$ момент
называют\ж начальным\н, а при~$x_0=\mean{X}$~---\ж центральным\н.
В частности, моменты нулевого порядка равны~1, начальный момент
первого порядка равен математическому ожиданию случайной величины; центральный
момент первого порядка равен нулю.

Центральный момент второго порядка называют\ж
дисперсией\н\index{Дисперсия}:
$$D(X)=\mean{(x-\mean{x})^2}.$$
Разброс случайной величины относительно математического ожидания
характеризуется\ж средним квадратическим
отклонением\н\index{Среднее квадратическое отклонение}~$\sigma=\sqrt{D}$.
Дисперсию можно вычислить и по упрощенному выражению:
$$D=\mean{(x-\mean{x})^2}=\mean{x^2}-\mean{2x\mean{x}}+\mean{\mean{x}^2}=
\mean{x^2}-\mean{x}^2\equiv M(x^2)-[M(x)]^2.$$

Дисперсия обладает следующими\к свойствами\н:
\begin{itemize}
\item $D(\const)=0$;
\item $D(\C X)=C^2 D(X)$, где $\C$~-- постоянная величина;
\item $D(\sum X_n)=\sum D(X_n)$.
\end{itemize}


\subsection{Законы распределения}
\bf Законом распределения\н\index{Закон!распределения}\к дискретной\н случайной
величины называют соответствие между возможными значениями и их вероятностями.
Его можно задать таблично, аналитически (в виде формулы) и графически.

Вероятность того, что значения случайной величины не превышают заданного
числа~$x$
называют\ж функцией распределения\н\index{Функция!распределения}:
$$F(x)\equiv P(X\le x)=\Int_{-\infty}^x\phi(x)\,dx.$$
Так как вероятность попадания значений~$(X)$ в промежуток~$(-\infty,\infty)$
равна
единице, плотность вероятности должна быть\ж нормирована\н\index{Нормировка}:
$$\Infint\phi(x)\,dx=1.$$
\it Вероятность того, что непрерывная случайная величина~$X$ примет одно
определенное значение равна нулю\н.

Исходя из смысла функции распределения, можно рассчитать вероятность того, что
случайная величина примет значение, заключенное в интервале~$[a,b]$:
$$P(a\le X\le b)=F(b)-F(a).$$

Наиболее известными законами распределения
являются равномерное, нормальное (гауссово), Пуассона, биномиальное,
экспоненциальное.

Говорят, что случайная величина имеет непрерывное\ж равномерное
распределение\н\index{Распределение!равномерное}
на
отрезке~$[a,b]$, где~$a$,~$b\in\mathbb{R}$, если ее плотность $\phi(x)$ имеет
вид
$$
\phi(x)=\begin{cases}\frac1{b-a}, & x\in [a,b] \\ 0, & x\not\in [a,b]
\end{cases}.
$$
Интегрируя, получим, для~$F(x)$:
$$F(x)= \begin{cases} 0, & x < a \\ {x-a \over b-a}, & a \le x < b \\ 1, & x \ge
b \end{cases}.
$$
Математическое ожидание и медиана для равномерного распределения совпадают с
серединой
отрезка~$[a,b]$, модой же является любое значение из этого отрезка.

\bf Биномиальным\н\index{Распределение!биномиальное} называют распределение
вероятностей, определяемое\ж формулой Бернулли\н\index{Формула Бернулли}
$$P_n(k)=C_n^k p^k q^{n-k},\quad C_n^k=\frac{n!}{k!(n-k)!},\quad
q=1-p.$$
Закон назван биномиальным, т.к. его можно рассматривать как общий член
разложения бинома Ньютона:
$$(p+q)^n=C_n^n p^n+\cdots+C_n^k p^k q^{n-k}+\cdots+C_n^0 q^k.$$
Таким образом, биномиальный закон описывает вероятность наступления события~$k$
раз в~$n$ независимых испытаниях~\look{binopdf}.

\begin{pict}
\includegraphics[width=.8\textwidth]{pic/binopdf}
\caption{Биномиальное распределение с~$n=100$ и~$p=0.5$ (пунктир). Для
сравнения приведено нормальное распределение с~$\mean{x}=50$ и~$\sigma=7$
(сплошная линия)}
\label{binopdf}
\end{pict}

Если количество испытаний~$n$ велико, можно воспользоваться асимптотической
формулой Лапласа. Однако, формула Лапласа непригодна, если $p\le0.1$. В этих
случаях прибегают к асимптотической формуле Пуассона.
При этом необходимо сделать важное допущение: произведение $np=\lambda$ должно
сохранять постоянное значение (т.е. число появления событий в различных сериях
испытаний остается неизменным).
В этом случае формула Бернулли примет вид:
$$P_n(k)=C_n^k\Bigl(\frac{\lambda}{n}\Bigr)^k\Bigl(1-
\frac{\lambda}{n}\Bigr)^{n-k}.$$
Так как $n$ велико, вместо $P_n(k)$ будем искать $\lim_{n\to\infty}P_n(k)$:
$$P_n(k)\approx \frac{\lambda^k}{k!}\lim_{n\to\infty}
\frac{\overbrace{n(n-1)\cdots[n-(k-1)]}^{\text{$k$ множителей}}}{n^k}
\Bigl(1-\frac{\lambda}{n}\Bigr)^{n-k}=\frac{\lambda^k}{k!}\exp(-\lambda).$$
Эта формула выражает закон\ж распределения
Пуассона\н\index{Распределение!Пуассона} вероятностей массовых и редких
событий~\look{poissonpdf}.

\begin{pict}
\includegraphics[width=.7\textwidth]{pic/poissonpdf}
\caption{Распределение Пуассона с~$\lambda=50$ (пунктир). Для
сравнения приведено нормальное распределение с~$\mean{x}=50$ и~$\sigma=7$
(сплошная линия)}
\label{poissonpdf}
\end{pict}

Важнейшую роль в физике имеет\ж
нормальное\н\index{Распределение!нормальное}~(гауссово) распределение.
Физическая величина подчиняется нормальному распределению, когда она подвержена
влиянию огромного числа случайных помех. Плотность вероятности нормального
распределения имеет вид~\look{normpdf}:
$$
\phi (x) = \frac 1 {\sigma \sqrt {2 \pi}} \exp \left( -\frac {(x -\mean{x})^2}{2
\sigma^2} \right),
$$
Функция распределения Гаусса записывается через\к интеграл
Римана\н\index{Интеграл Римана}:
$$
F (x) = \frac 1{\sigma \sqrt {2 \pi}} \Int_{-\infty}^x \exp \left( -\frac{(t
-\mean{x})^2}{2 \sigma^2} \right)\, dt.
$$
Особенностью нормального распределения является совпадение медианы, моды и
математического ожидания.

\begin{pict}
\includegraphics[width=.8\textwidth]{pic/normpdf}
\caption{Нормальное распределение с~$\mean{x}=5$ и~$\sigma=0.5$. Вертикальными
пунктирными линиями обозначены границы $\mean{x}\pm\sigma$}
\label{normpdf}
\end{pict}

Вероятность того, что нормальная случайная величина с параметрами~$\mean{x}$
и~$\sigma$
попадет в интервал $(\alpha,\beta)$ равна:
$$
P(\alpha < X < \beta) = \Phi\Bigl( \frac {\beta - \mean{x}} {\sigma}\Bigr) -
\Phi\Bigl( \frac {\alpha - \mean{x}} {\sigma}\Bigr),
$$
где $\Phi(x)$~--\ж функция Лапласа\н:
$$
\Phi(x)= \frac 1 {\sqrt {2 \pi}} \Int _{0}^x \exp \Bigl( -\frac {t^2} {2}
\Bigr) dt.
$$

\bf Показательным\н
(экспоненциальным)\index{Распределение!экспоненциальное}~\look{exppdf}
называют распределение вероятностей непрерывной случайной величины~$X$, которое
описывается плотностью
$$f(x)=\begin{cases}
0,& x<0,\\
\lambda\exp(-\lambda x),& x\ge0;
\end{cases}\qquad
F(x)=\begin{cases}
0,& x<0,\\
1-\exp(-\lambda x),& x\ge0,
\end{cases}
$$
где $\lambda$~--- постоянная положительная величина.

\begin{pict}
\includegraphics[width=.7\textwidth]{pic/exppdf}
\caption{Экспоненциальное распределение с~$\lambda=17$ (пунктир). Для
сравнения приведено нормальное распределение с~$\mean{x}=0$ и~$\sigma=7$
(сплошная линия)}
\label{exppdf}
\end{pict}

Для показательного распределения вероятность попадания случайной величины в
интервал~$[a,b]$ равна
$$P(a\le X\le b)=\exp(-\lambda a)-\exp(-\lambda b).$$

Экспоненциальное распределение замечательно тем, что оно описывается лишь одним
параметром~$\lambda$, через который вычисляются и другие характеристики:
$\mean X=\sigma_X=1/\lambda$, $D(X)=1/\lambda^2$.

\subsection{Корреляция и ковариация}
Для выяснения зависимости случайных величин~$X$ и~$Y$ используются такие
функции, как
корреляция и ковариация.\ж Ковариация\н\index{Ковариация} является мерой
линейной зависимости случайных величин и определяется формулой:
$\mathrm{cov}(X,Y)=\mean{(X-\mean{X})(Y-\mean{Y})}$.
Понятно, что ковариация величины с самой собой есть ее дисперсия.\к Ковариация
независимых случайных величин равна нулю\н, обратное неверно.

\bf Коэффициент корреляции\н\index{Коэффициент!корреляции} двух величин задается
формулой
$$
\rho_{X,Y} = \frac{\mathrm{cov}(X,Y)}{\sqrt{D(X) \cdot D(Y)}}.
$$
\it Коэффициент корреляции равен~$\pm1$ тогда и только тогда, когда~$X$ и~$Y$
линейно
зависимы\н. Если они независимы, $\rho_{X,Y}=0$. Промежуточные значения
коэффициента
корреляции не позволяют однозначно судить о зависимости случайных величин, но
позволяет предполагать степень их зависимости.

Для непрерывных величин аналогом коэффициента корреляции является\к
корреляционная
функция\н. Более часто применяют ее разновидность~---\ж автокорреляционную
функцию\н:\index{Функция!автокорреляционная}
$$
\Psi(\tau) = \Int f(t) f(t-\tau)\, dt\equiv
\Int f(t+\tau) f(t)\,dt,
$$
показывающую связь сигнала (функции $f(t)$) с копией самого себя, смещенного на
величину~$\tau$.
Для дискретных случайных величин автокорреляционная функция имеет вид
$$
\Psi(\tau) = \aver{X(t)X(t-\tau)}\equiv\aver{X(t+\tau)X(t)},
$$
где усреднение производится по всем временам~$t$.

Автокорреляционная функция имеет обычно максимум при~$\tau=0$. Имея два сигнала,
представляющих собой исходный и сдвинутый на неизвестную величину~$z$, можно
определить~$z$ из корреляционной функции: эту величину однозначно покажет
положение максимума корреляционной функции~\look{autocorr}.

\begin{pict}
\includegraphics[width=.7\textwidth]{pic/autocorr}
\caption{Участок корреляционной функции двух синусоид, сдвинутых друг
относительно друга на~$0.1$~с}
\label{autocorr}
\end{pict}


\subsection{Шум}
В теории сигналов вводят понятие шума.\ж Шум\н\index{Шум}~--- беспорядочные
колебания различной физической природы, отличающиеся сложной временной и
спектральной структурой. В радиоэлектронике под шумом принято понимать любые
нежелательные возмущения, как правило, аддитивно накладывающиеся на полезный
сигнал и искажающие его. 

Шум может носить как случайный, так и систематический характер. Значительно
снизить уровень шума возможно при переходе от аналоговых к цифровым сигналам,
т.к. каждая единица информации при этом может принимать лишь дискретные
значения: промежуточные значения при этом явно будут вызваны шумом.

\begin{pict}
\includegraphics[width=\textwidth]{pic/SNR}
\caption{Синусоида $y=\sin(x)$ с аддитивным белым шумом с $SNR=10$,
$0$, и~$-10$~дБ (сверху вниз)}
\label{SNR}
\end{pict}

Наиболее общим видом шума является\ж белый шум\н\index{Белый шум}~--- шум, время
корреляции которого много меньше всех характерных времен физической системы.
Иными словами, это стационарный шум, спектральные составляющие которого
равномерно распределены по всему диапазону задействованных частот.
Математической моделью белого шума является случайный процесс~$\xi(t)$
(важно отметить, что $\mean{\xi(t)}=0$) с автокорреляционной функцией
$$\Psi(t,\tau)=\aver{\xi(t+\tau)\xi(t)}=\sigma^2(t)\delta(\tau).$$
Здесь $\delta(t)$~-- дельта-функция Дирака, $\sigma^2(t)$~-- интенсивность
белого шума.

В случае стационарного процесса $\sigma^2(t)=\const$ и спектр шума является
равномерным:
$$\tilde\Psi(\omega)=\rev{2\pi}\Infint\Psi(\tau)\exp(-i\omega\tau)\,d\tau=
\frac{\sigma^2}{2\pi}.$$

В природе и технике <<чисто>> белый шум (то есть белый шум, имеющий одинаковую
спектральную мощность на всех частотах) не встречается (ввиду того, что\к такой
сигнал имел бы бесконечную мощность\н), однако под категорию белых шумов
попадают любые шумы, спектральная плотность которых одинакова (или слабо
отличается) в рассматриваемом диапазоне частот~\look{SNR}.
Белым шумом является любой шум с фиксированной дисперсией, нулевым
математическим ожиданием и автокорреляционной функцией, имеющей вид
дельта-функции Дирака. Чаще всего белый шум моделируют гауссовским
распределением, т.к. такая модель хорошо подходит для математического описания
многих природных процессов.

Зашумленность сигнала характеризуют\ж отношением
сигнал/шум\н~(SNR):\index{Отношение сигнал/шум}
$$
\mathrm{SNR} = {P_\mathrm{signal} \over P_\mathrm{noise}} = \left (
{A_\mathrm{signal} \over A_\mathrm{noise} } \right )^2,
$$
где $P$ и~$A$~--- соответственно, средняя мощность и среднеквадратичное значение
амплитуды сигнала и шума. Зачастую~SNR выражают в~децибелах:
$$
\mathrm{SNR (dB)} = 10 \lg \left ( {P_\mathrm{signal} \over P_\mathrm{noise}}
\right )
= 20 \lg \left ( {A_\mathrm{signal} \over A_\mathrm{noise}} \right ).
$$
Причина множителя 10 становится понятной, исходя из приставки <<деци>>, а
множитель~20 возникает вследствие умножения на 2, появляющегося при логарифмировании
амплитуд.






\pract
\subsection{Основы}
Познакомимся со средой матричных вычислений GNU/Octave (аналог Matlab) и научимся
выполнять в нем простейшие манипуляции с данными.

Все данные в Octave представлены в матричной форме.\к Этого не следует забывать при
выполнении различных операций\н! Чтобы присвоить переменной~$A$ значение 10.5,
достаточно написать: \verb'A=10.5'. На экране тут же отобразится значение
переменной~$A$.\к Для подавления вывода следует заканчивать команды точкой с
запятой\н. Попробуйте набрать теперь \verb'A=10.5;' заметили разницу?

Если вы хотите инициализировать эту переменную
вектором, напишите, например: \verb'A=[1 2 3]' или же \verb'A=[1,2,3]'. Вы
получите вектор-строку с элементами~1, 2 и~3. Таким образом, перечислять элементы
строки можно либо через запятую, либо через пробел. Чтобы получить вектор-столбец,
следует разделять его элементы точкой с запятой: \verb'A=[1;2;3]'.
И, наконец, для ввода матриц: разделяйте элементы строки запятыми или пробелами,
а строки~--- точкой с запятой. Введем единичную матрицу:
$$\verb'A=[1 0 0;0 1 0;0 0 1]'$$
на экране отобразится:
\begin{lstlisting}
A =
    1  0  0
    0  1  0
    0  0  1
\end{lstlisting}


Для обращения к элементу матрицы необходимо набрать его имя и в скобках указать
либо абсолютный номер, либо\к номер строки, а затем номер столбца\н. Наберите
теперь \verb'A(5)', а после~--- \verb'A(2,2)'. На экране отобразится один и
тот же текст: \verb'ans=1'. И действительно, пятый по счету элемент соответствует
элементу второй строки второго столбца. Программистам следует обратить внимание,
что\к номера массивов начинаются с единицы\н, в отличие от языков программирования,
где первому элементу соответствует ноль.

Допустим, у вас есть матрица-строка, а вы хотите сделать матрицу-столбец. Для
этого используйте операцию транспонирования: наберите \verb'x=[1 2 3]', а затем
\verb"x'". Как видите, добавление после имени матрицы апострофа означает
операцию транспонирования.

\bf Диапазоны данных\н можно указывать, разделяя числа двоеточием. Так,
\verb'[1:10]' дает набор целых чисел от~1 до~10, а \verb'[1:0.5:10]'~---
то же, но с шагом в~$0.5$.

Теперь создайте еще одну матрицу
$$\verb'a=[0 1 0;1 0 1;0 1 0]'$$
Заодно обратите
внимание:\к в Octave имена переменной зависят от регистра\н! Для произведения
простейших операций над матрицами используйте операторы +, -, / и \verb'*'.
Наберите поочередно \verb'A+a', \verb'A-a', \verb'A*a', \verb'A/a'. Обратите
внимание, что при этом производятся именно матричные операции. Поэтому необходимо
согласовывать размеры матриц (вспомните курс алгебры). Еще одним, чисто матричным
оператором, является оператор левого деления \verb'\', использующийся при
решении систем уравнений. Кроме того, используется оператор возведения в
степень, \verb'^'.

Но, допустим, вы захотите произвести поэлементное умножение или деление матриц.
В этом случае\к до символа операции наберите точку\н. Например, попробуйте
набрать \verb'A./a'. Попробуйте эти операции с более осмысленными векторами или
матрицами.

Если вы присвоили переменной\к одно\н значение, все вычисления с ней выполняются
как со скаляром.

Кроме чисел в Octave есть понятия бесконечности (\verb'Inf') и не-числа
(\verb'NaN'). Вы можете присвоить эти величины переменным. Обратите внимание, что
\verb'NaN' соответствует неопределенным операциям, например, пределам вида $0/0$,
$\infty/\infty$ и т.п. (однако, попробуйте операцию \verb'Inf/0').
В отличие от \verb'Inf', \verb'NaN' инвариантен относительно любых операций.

Еще одним удобством является дополнение команд и <<история команд>> в стиле UNIX. Набирая
команду и нажимая клавишу Tab вы упростите себе работу: если вариант дополнения
только один, Octave закончит команду, иначе~--- выведет окно выбора со списком
возможных команд. Клавишами $\uparrow$ и $\downarrow$ можно перемещаться по
истории команд, что полезно, если вам надо набирать много однотипных длинных
команд, отличающихся незначительно. Для быстрого поиска по истории, если вы знаете, как
должна начинаться нужная строка с командами, наберите первые символы ее начала и нажмите
клавишу $\uparrow$.

В Octave существует огромное количество функций (посмотреть все их названия можете, нажав Tab и y).
Обычно они имеют стандартный синтаксис типа \verb'A=funk(b,...)': аргументы функции помещаются
в скобки, а ее значение приравнивается матрице. Краткую помощь по функции \verb'function' можно
получить командой \verb'help function', более подробное руководство вызывается командой
\verb'doc function'.

\next
Для генерации синусоидального сигнала $y_0=A\sin(2\pi t/T)$ с амплитудной модуляцией
по закону $y_1=f(t)$ необходимо перемножить эти две функции: $y=y_0\cdot y_1$.
Промодулируем синусоиду с периодом $\pi/5$ пилообразным сигналом с периодом~10
на интервале $x\in[0,20]$.

Если интервал $[0,20]$ мы зададим командой \verb'x=[0:20];', то точек получится слишком мало, и
график будет выглядеть некрасиво. Поэтому зададим интервал с шагом $\Delta x=0.05$, для чего дадим
команду \verb'x=[0:0.05:20];'. Выражение \verb'[a:b:c]' возвращает вектор-строку от~$a$ до~$c$ с
шагом~$b$.

Для генерирования <<пилы>> используется функция \verb'sawtooth'. Если задать
ей один аргумент (вектор $x$), период будет равен~$2\pi$, а сигнал будет
изменяться в интервале $[-1,1]$. Чтобы задать смещение максимума, равное $a\cdot2\pi$,
необходимо указать: \verb'y=sawtooth(x,a)'. Таким образом, чтобы получить
<<пилу>> с интервалом сигнала в $[0,1]$ и периодом~10, необходимо дать команду
\verb'y1=0.5+sawtooth(x*2*pi/10)/2;'. Следовательно, получить наш сигнал можно
командой
$$\verb'y=sin(x*10).*(0.5+sawtooth(x*pi/5)/2);'$$
Не забудьте про точку перед знаком умножения между функциями, иначе
получите ошибку, т.к. Octave попытается перемножить два вектора--строки.\к Операторы с точкой\н
(вида \verb'.*', \verb'./', \verb'.^') \к выполняются почленно\н. Если обе переменных, над которыми
мы выполняем операцию с точкой, имеют одинаковый вид (векторы-столбцы или векторы-строки),
результатом будет аналогичный вектор, каждый член которого будет являться результатом действия
данного оператора на соответствующие члены векторов-переменных. Если векторы ортогональны,
результатом будет матрица "--- почленное умножение первого вектора на второй (с предупреждением об
автоматической операции расширения векторов):
\begin{lstlisting}
[1:3] .* [3:5]'
warning: product: automatic broadcasting operation applied
ans =

    3    6    9
    4    8   12
    5   10   15

[1:3]' .* [3:5]
warning: product: automatic broadcasting operation applied
ans =

    3    4    5
    6    8   10
    9   12   15
\end{lstlisting}
Апостроф в данном случае означает\к операцию транспонирования матрицы\н.
С двумерными матрицами разных размеров операция почленного умножения не сработает:
\begin{lstlisting}
a=[1 2 3; 4 5 6]; b = [1 1 1; 2 2 2];

a .* b
ans =

    1    2    3
    8   10   12

a' .* b'
ans =

    1    8
    2   10
    3   12

a .* b'
error: product: nonconformant arguments (op1 is 2x3, op2 is 3x2)
\end{lstlisting}



\subsection{Статистика}
Теперь познакомимся с командой \verb'rand'. Эта команда\к генерирует равномерно
распределенные случайные числа из диапазона~$[0,1]$\н. Создайте вектор-строку из ста случайных чисел
командой \verb'a=rand(1,100);'. Не забывайте писать в конце команд точку с запятой,
иначе вывод (особенно для больших массивов) может занять длительное время.
Командой \verb'x=rand(100,100);' можно создать массив из $100\times100$ случайных
чисел. Аналогично ведет себя команда \verb'x=rand(100);'.

Для\ж отображения графиков\н в Octave есть команда \verb'plot', которая использует интерфейс
gnuplot. Если ей задан один аргумент, она отображает по оси X номер элемента, а по Y~--- его
значение. Если задать аргументами массивы\к одинаковой\н длины, первый используется как
значения оси X, второй~--- Y. Постройте график \verb'plot(a)'. Убедились,
что $a$~--- массив совершенно случайных чисел?

Закрыть окно с графиком можно командой \verb'close' (лучше пользоваться ею, т.к. принудительное
закрытие окна gnuplot может привести к отказу его работы при следующем выводе графика).

Команда \verb'mean(a)' вернет среднее арифметическое значение переменной $a$\к
по столбцам\н (если $a$~-- вектор-строка, то \verb'mean' посчитает среднее по всем его значениям).
Вторым аргументом команды можно указать, по какому именно столбцу мы хотим усреднить массив~$a$.
Найдите среднее значение своего вектора. Отобразите на графике все значения
и их среднее командой
$$\verb'plot([1:100], a, [1 100], mean(a)*[1 1])'$$
Обратите внимание на то, что \verb'plot' позволяет сразу рисовать несколько графиков, если
перечислять соответствующие им абсциссы и ординаты поочередно. Конструкция
$$\verb'mean(a)*[1 1]'\qquad\text{(или}\qquad
\verb'mean(a)*ones(1,2)'\text{)}$$
нужна для согласования размера вектора данных абсцисс и ординат точек графика.

Если точки двух графиков по оси~$X$ совпадают (как в предыдущем случае),
можно укоротить запись:
$$\verb'plot([1:100],[a; mean(a)*ones(1,100)])'$$
(команда \verb'plot', если задать ей в качестве аргумента матрицу, изображает
разными цветами графики функций, соответствующих каждой строке матрицы).

Функция \verb'normpdf(X,x,s)' позволяет построить график нормального распределения,
соответствующий вектору координат~$X$, для математического ожидания~$x$ и среднего
квадратичного отклонения~$s$. Наберите
$$\verb'x=[-70:30]; y=normpdf(x,-20,20);'$$
а затем~--- \verb'plot(x,y)'. На графике вы увидите плотность вероятности нормально
распределенной случайной величины с математическим ожиданием~$-20$ и среднеквадратичным
отклонением~$20$.

По мере выполнения заданий у вас будет накапливаться все больше и больше занимающих память ненужных
данных. Посмотреть, сколько памяти какие переменные занимают, можно командой \verb'whos'.
Не обращайте внимания на переменную \verb'ans' "--- это автоматическая переменная, в которую
заносится результат последней выполненной операции (и ее, кстати, можно использовать в вычислениях).
Чтобы удалить те или иные переменные, используйте функцию \verb'clear var': она удалит из памяти
переменную \verb'var'. Пользуйтесь этой функцией с осторожностью: без аргумента она полностью
удалит все переменные из памяти Octave.

Сгенерируем синусоидальный сигнал на участке~$[0,2\pi]$ командами
$$\verb'x=[0:pi/50:2*pi]; y=sin(x);'$$
Теперь добавим к сигналу
гауссов белый шум с амплитудой 10~дБ относительно амплитуды сигнала:
$$\verb"y1=awgn(y,10,'measured'); plot(x, [y; y1])"$$
Третий параметр (\verb'measured') обязателен, т.к. без него процесс добавления
шума будет несколько иным (мощность сигнала будет считаться равной 0~дБ), можете
проверить на синусоиде с амплитудой~10. По умолчанию в Octave функция \verb'awgn' недоступна: для
того, чтобы пользоваться ею, необходимо установить пакет octave-communications.


\subsection{Корреляция}
Создадим теперь две синусоиды, сдвинутые по фазе на угол~$0.3$:
\verb'x=[0:0.05:20];' \verb'y=sin(x);'
\verb'y1=sin(x+0.3);'. Попробуем определить, на сколько единиц сдвинут первый
сигнал относительно второго. Для этого воспользуемся корреляционной функцией.
Запишем \verb'Corr=xcorr(y,y1);'.

Функция \verb'xcorr' входит в пакет \verb'signal'. Если он не загружен автоматически при запуске
Octave, его можно загрузить командой \verb'pkg load signal'. В таком виде, как мы ее записали,
функция \verb'xcorr' ничем не отличается от функции \verb'corr', возвращающей кросс-корреляционную
функцию двух векторов. Однако, \verb'xcorr' позволяет производить кое-какие манипуляции с
возвращаемыми данными. Общий формат ее (читайте справку, \verb'help xcorr') таков:
$$\verb'[R, lag] = xcorr (X [, Y] [, maxlag] [, scale])'$$
Второй (опциональный) возвращаемый
аргумент (\verb'lag') "--- вектор значений сдвигов в единицах исходных данных. \verb'maxlag'
позволяет <<обрезать>> выходные данные по амплитуде абсциссы. \verb'scale' "--- изменить амплитуду
кросс-корреляционной функции: если \verb'scale' имеет значение \verb"'biased'", то амплитуда
делится на количество отсчетов исходных данных; \verb"'unbiased'" делит амплитуду на число $N-|k|$,
где $N$~-- количество отсчетов исходных данных, $k$~-- абсцисса (\verb'lag') кросс-корреляционной
функции; \verb"'coeff'" возвращает корреляционную функцию, нормированную на среднеквадратичные
отклонения~$X$ и~$Y$ (т.е. по сути возвращает корреляционные коэффициенты).

Таким образом, для правильного построения кросс-корреляционной функции в данном случае необходимо
выполнить
$$\verb"[Corr, lag]=xcorr(y,y1,20,'coeff'); plot(lag*0.05,Corr)"$$
Вектор \verb'lag' необходимо умножить на шаг абсциссы ($0.05$), т.к. в оригинале он содержит \ж
отсчеты\н, а не исходные координаты (о них \verb'xcorr' и не знает).

На построенном графике мы видим, что максимум кросс-корреляционной функции сдвинут относительно нуля
вправо на~$0.25$. Это значит, что первый аргумент функции \verb'xcorr' скорее всего сдвинут
относительно второго на~$0.25\pm0.05$ вправо. Убедиться в том, что это действительно сдвиг одной и
той же функции, мы можем, сравнив автокорреляционные функции данных:
\begin{lstlisting}
[aCorr, lag]=xcorr(y,[],[],'coeff');
[bCorr, lag]=xcorr(y1,[],[],'coeff');
plot(lag*0.05,[aCorr;bCorr])
\end{lstlisting}
В пределах первого <<горба>> они совпадают, далее же наблюдаются различия по амплитуде из-за
ограниченности наших сигналов. Таким образом, мы смело можем сделать вывод о сдвиге одной функции
относительно другой по виду кросс-корреляционной функции с точностью до квантования отсчетов
абсциссы.

В нашем случае сигнал был периодическим, поэтому при сдвигах на величины, превышающие половину
периода, возникает ошибка, кратная полупериоду. Это необходимо учитывать в расчетах. Можете
попробовать сдвинуть~$y_1$ относительно~$y$, например, на~4 и посмотреть, что получится в
результате (ограничивать по абсциссе в этом случае кросс-корреляционную функцию не надо).

\self
\begin{enumerate}
\item Найдите сумму, разность, произведение и частное матриц
$$A=\begin{pmatrix}1&2&3\\6&5&4\\9&8&7\end{pmatrix},\qquad
B=\begin{pmatrix}9&8&7\\5&3&1\\0&2&6\end{pmatrix}.$$
Найдите определители исходных и получившихся матриц (команда \verb'det(A)').

\item
Найдите значение почленного, матричного и скалярного произведений векторов
$a=(2,5,7)$ и $b=(11,13,17)$. Скалярное произведение найдите двумя способами:
путем перемножения векторов и при помощи функции \verb'dot(a,b)'.
Найдите векторное произведение $a\times b$ при помощи функции
\verb'cross(a,b)'.

\item
Постройте график нормального распределения на интервале $[0,100]$ с математическим
ожиданием~50 и дисперсией~100.

\item
\label{noicy_AM}
Получите сигнал с амплитудной модуляцией (из примера). Добавьте к нему гауссов
белый шум с SNR 100, 50, 10 и~1~дБ. Постройте отдельно графики всех
полученных сигналов. Можно ли сделать какой-либо вывод о виде сигнала при
SNR=1? Как вы думаете, можно ли восстановить из него исходный сигнал?

\item
Для полученного сигнала найдите следующие характеристики: математическое ожидание
(\verb'mean'), среднее квадратичное отклонение (\verb'std'), медиану (\verb'median')
и моду (\verb'mode'). Найдите аналогичные величины для разности между зашумленным
и оригинальным сигналом. Сравните полученные величины с теоретическими.

\item
Попытайтесь определить сдвиг двух синусоид (из примера) при зашумлении:
\begin{itemize}
\item только одной с уровнем сигнал/шум 1~дБ;
\item обеих с уровнем SNR=1~дБ;
\item одной с уровнем SNR=0.1~дБ;
\item обеих с уровнем SNR=0.1~дБ.
\end{itemize}
Постройте один из сигналов с SNR=0.1~дБ. Можно ли определить его период?
Можно ли определить период по автокорреляционной функции этого сигнала?
\end{enumerate}

\qwest
\begin{enumerate}
\item Что называют случайной величиной? Вероятностью? Плотностью вероятности?
В чем отличие непрерывных и дискретных случайных величин?
\item Что такое функция распределения вероятности? Для чего используется
нормировка функции распределения?
\item Дайте определения медианы, моды, математического ожидания,
дисперсии и среднеквадратичного отклонения.
\item Можно ли считать равными среднее арифметическое и математическое
ожидание? Какой закон описывает сходство этих величин?
\item Что называют центральными, начальными моментами? Чему равен центральный
момент первого порядка?
\item Какие основные распределения случайных величин вы знаете?
Какому распределению подчиняются большинство физически наблюдаемых
случайных величин?
\item Для чего используется функция Лапласа?
\item Что такое ковариация, корреляция? Для чего при расчете коэффициента
корреляции ковариацию делят на среднее геометрическое дисперсий случайных
величин?
\item Для чего при исследовании двух сигналов применяется корреляционная функция?
\item Дайте определение белого шума. Почему шум такого вида не существует в
природе?
\item Какая характеристика описывает чистоту сигнала? Объясните, от чего зависит
коэффициент при расчете этой характеристики в логарифмической шкале.
\item Дайте определения скалярного, векторного и тензорного произведения
двух векторов. Как в Octave реализуются эти операции?
\end{enumerate}


\addition
\subsection{Генератор случайных чисел}
Во многих задачах математического моделирования требуется генерировать случайные числа,
подчиняющиеся определенному закону распределения. Для этого прежде всего необходимо иметь надежный
генератор равномерно распределенных случайных чисел. Простейшие алгоритмы (функция \verb'rand')
позволяют получить набор\к псевдослучайных чисел\н\index{Псевдослучайное число}, которые,
во-первых, не являются действительно случайными (и можно предугадать последовательность таких
чисел, имея одно), а во-вторых, плохо укладываются под случайное распределение.

В криптографии процесс получения действительно случайных величин настолько важен, что для этих целей
используются всевозможные аппаратные генераторы (чаще всего работающих на основе обработки тем или
иным образом полученного белого шума). В математическом моделировании эта задача не столь важна,
поэтому можно воспользоваться более дешевым способом: использовать стандартный программный
генератор, но инициализировать его периодически на основе действительно случайных величин.

В Linux существует два псевдоустройства, позволяющих получить случайные числа: \verb'/dev/urandom'
и \verb'/dev/random'. Первое генерирует случайные числа непрерывно, а второе "--- лишь при
накоплении достаточного количества <<энтропии>> "--- величины, полученной в результате обработки
разного рода псевдослучайных величин (состояния аппаратного обеспечения компьютера, нагрузки на
сеть, состояния работающего программного обеспечения, движения мыши и нажатий на клавиши
клавиатуры). Работу \verb'/dev/random' можно увидеть, запустив в терминале \verb'cat /dev/random' и
двигая мышью: чем активнее вы двигаете мышкой, тем чаще генерируются числа. Однако, генерируются они
довольно медленно по причине того, что \verb'/dev/random' "--- сложный генератор, который
используется в криптографических нуждах.

Постоянно читать случайные числа из \verb'/dev/urandom' мы не можем (лишние системные вызовы будут
замедлять работу программы), поэтому генерировать их лучше в своей программе. Инициализировать же
генератор лучше всего при помощи \verb'/dev/random'. Другой вариант инициализации "--- на основе
системного времени. Возможный вариант инициализации генератора псевдослучайных чисел представлен в
листинге~\ref{rand_ini}.

\listing{caption={Инициализация генератора псевдослучайных
чисел},label=rand_ini,language=C}{02/random_gen.c}

% Дописать:
% генерирование (C + Octave) случайных величин с произвольным видом распределений;
% вычисление медианы на сях
% оценка медианы и моды по гистограмме
% ?? нахождение прочих статистических величин (CUDA, openMP)
% 